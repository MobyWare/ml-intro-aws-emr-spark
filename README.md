# Goal
My initial foray into using ML and analysis workloads on AWS Elastic Map Reduce. By doing analysis on open source data I want to learn:
* More about doing data exploration with Spark on large data-sets
* More about doing ML on larger data sets
* Figure out when to use Spark based on data size versus R or Python
* More about Spark Configs for performance and scale
* Learn more about monitoring resource consumption during spark jobs

# Data
I plan to look at one or more data sets.

## Texas Hospital Administrative Discharge Data
Data set from [Hospital Discharge Data Public Use Data File](http://www.dshs.texas.gov/THCIC/Hospitals/Download.shtm) that looks at discharges from hospitals in Texas. You can get more information about the dataset from the [user manual](http://www.dshs.texas.gov/thcic/hospitals/UserManual2008.pdf).


