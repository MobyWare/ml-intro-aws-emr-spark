{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Goal\n",
    "### Overall Goal\n",
    "See how useful Spark is to explore a large data set.\n",
    "__*PUDF_base_all_tab.txt*__ is 10 GB and 18 M observations on over 250 features.\n",
    "\n",
    "### Specific to this notebook\n",
    "Explore how clean nine (9) columns of interest are:\n",
    "1. PROVIDER_NAME\n",
    "2. ADMIT_WEEKDAY\n",
    "3. pat_age\n",
    "4. RACE\n",
    "5. ETHNICITY\n",
    "6. FIRST_PAYMENT_SRC\n",
    "7. SECONDARY_PAYMENT_SRC\n",
    "8. ADMITTING_DIAGNOSIS\n",
    "9. TYPE_OF_ADMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from os import path, getcwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_distinct_number(df, col):\n",
    "    if df is None or col is None:\n",
    "        print(\"The dataframe or col is invalid\")\n",
    "        return sqlContext.createDataFrame(sc.emptyRDD(), StructType([]))\n",
    "    elif col not in df.columns:\n",
    "        print(\"The column '{}' is not in the dataframe.\" \\\n",
    "             .format(col))\n",
    "        return sqlContext.createDataFrame(sc.emptyRDD(), df.schema)\n",
    "    else:\n",
    "        return df.groupBy(col).count().count()\n",
    "\n",
    "def get_topN_group(df, col, sort=True, highest_first=True):\n",
    "    if df is None or col is None:\n",
    "        print(\"The dataframe or col is invalid\")\n",
    "        return \n",
    "    elif col not in df.columns:\n",
    "        print(\"The column '{}' is not in the dataframe.\" \\\n",
    "             .format(col))\n",
    "    else:\n",
    "        if sort:\n",
    "            return df.groupBy(col).count().orderBy(\"count\", ascending = not highest_first)\n",
    "        else:\n",
    "            return df.groupBy(col).count()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u\"Error while instantiating 'org.apache.spark.sql.hive.HiveSessionState':\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d50231c171e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Is there a Spark Context? {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m        \u001b[1;33m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local[*]\"\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SparkAnalysisDataQA\"\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\pyspark\\sql\\session.pyc\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessionState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetConfString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: u\"Error while instantiating 'org.apache.spark.sql.hive.HiveSessionState':\""
     ]
    }
   ],
   "source": [
    "try: \n",
    "    print(\"Is there a Spark Context? {}\".format(spark is None))\n",
    "except NameError as e:\n",
    "    spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName(\"SparkAnalysisDataQA\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d46314857636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtexas_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'com.databricks.spark.csv'\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PUDF_base_all_tab.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "texas_df = spark.read.format('com.databricks.spark.csv') \\\n",
    "    .options(header='true', inferschema='true', delimiter='\\t')\\\n",
    "    .load(path.join(getcwd(), \"..\", \"data\", \"PUDF_base_all_tab.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Exploration\n",
    "Looking at completeness of variables in __*goal*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discharge_qtr', 'thcic_id', 'PROVIDER_NAME', 'FAC_TEACHING_IND', 'FAC_PSYCH_IND', 'FAC_REHAB_IND', 'FAC_ACUTE_CARE_IND', 'FAC_SNF_IND', 'FAC_LONG_TERM_AC_IND', 'FAC_OTHER_LTC_IND', 'FAC_PEDS_IND', 'SPEC_UNIT_1', 'SPEC_UNIT_2', 'SPEC_UNIT_3', 'SPEC_UNIT_4', 'SPEC_UNIT_5', 'ENCOUNTER_INDICATOR', 'SEX_CODE', 'TYPE_OF_ADMISSION', 'SOURCE_OF_ADMISSION', 'PAT_STATE', 'PAT_ZIP', 'PAT_COUNTRY', 'county', 'public_health_region', 'ADMIT_WEEKDAY', 'LENGTH_OF_STAY', 'pat_age', 'PAT_STATUS', 'RACE', 'ETHNICITY', 'FIRST_PAYMENT_SRC', 'SECONDARY_PAYMENT_SRC', 'TYPE_OF_BILL', 'private_amount', 'semi_private_amount', 'ward_amount', 'icu_amount', 'ccu_amount', 'other_amount', 'pharm_amount', 'medsurg_amount', 'dme_amount', 'used_dme_amount', 'pt_amount', 'ot_amount', 'speech_amount', 'it_amount', 'blood_amount', 'blood_adm_amount', 'or_amount', 'lith_amount', 'card_amount', 'anes_amount', 'lab_amount', 'rad_amount', 'mri_amount', 'op_amount', 'er_amount', 'ambulance_amount', 'pro_fee_amount', 'organ_amount', 'esrd_amount', 'clinic_amount', 'total_charges', 'total_non_cov_charges', 'total_charges_accomm', 'total_non_cov_charges_accomm', 'total_charges_ancil', 'total_non_cov_charges_ancil', 'ADMITTING_DIAGNOSIS', 'PRINC_DIAG_CODE', 'OTH_DIAG_CODE_1', 'OTH_DIAG_CODE_2', 'OTH_DIAG_CODE_3', 'OTH_DIAG_CODE_4', 'OTH_DIAG_CODE_5', 'OTH_DIAG_CODE_6', 'OTH_DIAG_CODE_7', 'OTH_DIAG_CODE_8', 'OTH_DIAG_CODE_9', 'OTH_DIAG_CODE_10', 'OTH_DIAG_CODE_11', 'OTH_DIAG_CODE_12', 'OTH_DIAG_CODE_13', 'OTH_DIAG_CODE_14', 'OTH_DIAG_CODE_15', 'OTH_DIAG_CODE_16', 'OTH_DIAG_CODE_17', 'OTH_DIAG_CODE_18', 'OTH_DIAG_CODE_19', 'OTH_DIAG_CODE_20', 'OTH_DIAG_CODE_21', 'OTH_DIAG_CODE_22', 'OTH_DIAG_CODE_23', 'OTH_DIAG_CODE_24', 'PRINC_SURG_PROC_CODE', 'PRINC_SURG_PROC_DAY', 'PRINC_ICD9_CODE', 'OTH_SURG_PROC_CODE_1', 'OTH_SURG_PROC_DAY_1', 'OTH_ICD9_CODE_1', 'OTH_SURG_PROC_CODE_2', 'OTH_SURG_PROC_DAY_2', 'OTH_ICD9_CODE_2', 'OTH_SURG_PROC_CODE_3', 'OTH_SURG_PROC_DAY_3', 'OTH_ICD9_CODE_3', 'OTH_SURG_PROC_CODE_4', 'OTH_SURG_PROC_DAY_4', 'OTH_ICD9_CODE_4', 'OTH_SURG_PROC_CODE_5', 'OTH_SURG_PROC_DAY_5', 'OTH_ICD9_CODE_5', 'OTH_SURG_PROC_CODE_6', 'OTH_SURG_PROC_DAY_6', 'OTH_ICD9_CODE_6', 'OTH_SURG_PROC_CODE_7', 'OTH_SURG_PROC_DAY_7', 'OTH_ICD9_CODE_7', 'OTH_SURG_PROC_CODE_8', 'OTH_SURG_PROC_DAY_8', 'OTH_ICD9_CODE_8', 'OTH_SURG_PROC_CODE_9', 'OTH_SURG_PROC_DAY_9', 'OTH_ICD9_CODE_9', 'OTH_SURG_PROC_CODE_10', 'OTH_SURG_PROC_DAY_10', 'OTH_ICD9_CODE_10', 'OTH_SURG_PROC_CODE_11', 'OTH_SURG_PROC_DAY_11', 'OTH_ICD9_CODE_11', 'OTH_SURG_PROC_CODE_12', 'OTH_SURG_PROC_DAY_12', 'OTH_ICD9_CODE_12', 'OTH_SURG_PROC_CODE_13', 'OTH_SURG_PROC_DAY_13', 'OTH_ICD9_CODE_13', 'OTH_SURG_PROC_CODE_14', 'OTH_SURG_PROC_DAY_14', 'OTH_ICD9_CODE_14', 'OTH_SURG_PROC_CODE_15', 'OTH_SURG_PROC_DAY_15', 'OTH_ICD9_CODE_15', 'OTH_SURG_PROC_CODE_16', 'OTH_SURG_PROC_DAY_16', 'OTH_ICD9_CODE_16', 'OTH_SURG_PROC_CODE_17', 'OTH_SURG_PROC_DAY_17', 'OTH_ICD9_CODE_17', 'OTH_SURG_PROC_CODE_18', 'OTH_SURG_PROC_DAY_18', 'OTH_ICD9_CODE_18', 'OTH_SURG_PROC_CODE_19', 'OTH_SURG_PROC_DAY_19', 'OTH_ICD9_CODE_19', 'OTH_SURG_PROC_CODE_20', 'OTH_SURG_PROC_DAY_20', 'OTH_ICD9_CODE_20', 'OTH_SURG_PROC_CODE_21', 'OTH_SURG_PROC_DAY_21', 'OTH_ICD9_CODE_21', 'OTH_SURG_PROC_CODE_22', 'OTH_SURG_PROC_DAY_22', 'OTH_ICD9_CODE_22', 'OTH_SURG_PROC_CODE_23', 'OTH_SURG_PROC_DAY_23', 'OTH_ICD9_CODE_23', 'OTH_SURG_PROC_CODE_24', 'OTH_SURG_PROC_DAY_24', 'OTH_ICD9_CODE_24', 'E_CODE_1', 'E_CODE_2', 'E_CODE_3', 'E_CODE_4', 'E_CODE_5', 'E_CODE_6', 'E_CODE_7', 'E_CODE_8', 'E_CODE_9', 'E_CODE_10', 'CONDITION_CODE_1', 'CONDITION_CODE_2', 'CONDITION_CODE_3', 'CONDITION_CODE_4', 'CONDITION_CODE_5', 'CONDITION_CODE_6', 'CONDITION_CODE_7', 'CONDITION_CODE_8', 'OCCUR_CODE_1', 'OCCUR_DAY_1', 'OCCUR_CODE_2', 'OCCUR_DAY_2', 'OCCUR_CODE_3', 'OCCUR_DAY_3', 'OCCUR_CODE_4', 'OCCUR_DAY_4', 'OCCUR_CODE_5', 'OCCUR_DAY_5', 'OCCUR_CODE_6', 'OCCUR_DAY_6', 'OCCUR_CODE_7', 'OCCUR_DAY_7', 'OCCUR_CODE_8', 'OCCUR_DAY_8', 'OCCUR_CODE_9', 'OCCUR_DAY_9', 'OCCUR_CODE_10', 'OCCUR_DAY_10', 'OCCUR_CODE_11', 'OCCUR_DAY_11', 'OCCUR_CODE_12', 'OCCUR_DAY_12', 'OCCUR_SPAN_CODE_1', 'occur_span_from_1', 'occur_span_thru_1', 'OCCUR_SPAN_CODE_2', 'occur_span_from_2', 'occur_span_thru_2', 'OCCUR_SPAN_CODE_3', 'occur_span_from_3', 'occur_span_thru_3', 'OCCUR_SPAN_CODE_4', 'occur_span_from_4', 'occur_span_thru_4', 'VALUE_CODE_1', 'value_amount_1', 'VALUE_CODE_2', 'value_amount_2', 'VALUE_CODE_3', 'value_amount_3', 'VALUE_CODE_4', 'value_amount_4', 'VALUE_CODE_5', 'value_amount_5', 'VALUE_CODE_6', 'value_amount_6', 'VALUE_CODE_7', 'value_amount_7', 'VALUE_CODE_8', 'value_amount_8', 'VALUE_CODE_9', 'value_amount_9', 'VALUE_CODE_10', 'value_amount_10', 'VALUE_CODE_11', 'value_amount_11', 'VALUE_CODE_12', 'value_amount_12', 'HCFA_MDC', 'APR_MDC', 'HCFA_DRG', 'APR_DRG', 'RISK_MORTALITY', 'ILLNESS_SEVERITY', 'attending_phys_unif_id', 'operating_phys_unif_id', 'cert_status', 'record_id', 'INBOUND_INDICATOR']\n"
     ]
    }
   ],
   "source": [
    "texas_df_columns = texas_df.columns\n",
    "print(texas_df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LOS & PAT_AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are non-numerics for LOS and POS.\n",
      "# LOS with value 'LENGTH_OF_STAY': 3.\n",
      " # LOS with value '*': 8181. \n",
      "# PAT_AGE with value '*': 983.\n",
      "# PAT_AGE with value 'ZZ': 152283.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are non-numerics for LOS and POS.\\n\" + \\\n",
    "      \"# LOS with value 'LENGTH_OF_STAY': {}.\\n \"\\\n",
    "      .format(\n",
    "        texas_df.filter(texas_df[\"LENGTH_OF_STAY\"] == 'LENGTH_OF_STAY').count()) + \\\n",
    "      \"# LOS with value '*': {}. \\n\" \\\n",
    "      .format(\n",
    "      texas_df.filter(texas_df[\"LENGTH_OF_STAY\"] == '*').count()) + \\\n",
    "      \"# PAT_AGE with value '*': {}.\\n\" \\\n",
    "      .format(\n",
    "      texas_df.filter(texas_df[\"PAT_AGE\"] == '*').count()) + \\\n",
    "      \"# PAT_AGE with value 'ZZ': {}.\" \\\n",
    "      .format(texas_df.filter(texas_df[\"PAT_AGE\"] == 'ZZ').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# distinct 'LENGTH_OF_STAY': 604.\n",
      "\n",
      "# distinct 'pat_age': 48.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"LENGTH_OF_STAY\", \"pat_age\"]:\n",
    "    print(\"# distinct '{}': {}.\\n\".format(col, get_distinct_number(texas_df, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|   LENGTH_OF_STAY|           PAT_AGE|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|         18114764|          18147843|\n",
      "|   mean|2.280949958520556|11.599688703625358|\n",
      "| stddev|9.438761332878363| 4.850573319201647|\n",
      "|    min|                *|                 *|\n",
      "|    max|   LENGTH_OF_STAY|                ZZ|\n",
      "+-------+-----------------+------------------+\n",
      "\n",
      "1 loop, best of 1: 1min 20s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.describe(\"LENGTH_OF_STAY\", \"PAT_AGE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Patient Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|SEX_CODE|  count|\n",
      "+--------+-------+\n",
      "|       F|1661639|\n",
      "|       M|1027482|\n",
      "|    null| 992226|\n",
      "|   88888| 102457|\n",
      "|   78521|  70316|\n",
      "|   78572|  63415|\n",
      "|       *|  60799|\n",
      "|   79936|  51113|\n",
      "|   78501|  50928|\n",
      "|   78577|  49470|\n",
      "|   75217|  48805|\n",
      "|   78539|  48298|\n",
      "|   75228|  42459|\n",
      "|   78596|  41771|\n",
      "|   78550|  41233|\n",
      "|   75211|  40880|\n",
      "|   78520|  40843|\n",
      "|   75216|  40407|\n",
      "|   77084|  39612|\n",
      "|   78207|  39258|\n",
      "+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 loop, best of 1: 7min 37s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.groupBy(\"SEX_CODE\").count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|LENGTH_OF_STAY|   count|\n",
      "+--------------+--------+\n",
      "|             2|10877316|\n",
      "|             1| 4410786|\n",
      "|          0002|  735987|\n",
      "|          0003|  467292|\n",
      "|          0001|  466910|\n",
      "|          0004|  268435|\n",
      "|          0005|  174801|\n",
      "|          0006|  130284|\n",
      "|          0007|  106240|\n",
      "|          0008|   76916|\n",
      "|          0009|   56394|\n",
      "|          0010|   44955|\n",
      "|          null|   43369|\n",
      "|          0011|   36529|\n",
      "|          0012|   28968|\n",
      "|          0013|   25607|\n",
      "|          0014|   24318|\n",
      "|          0015|   19085|\n",
      "|          0016|   15173|\n",
      "|          0017|   13030|\n",
      "+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 loop, best of 1: 3min 13s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.groupBy(\"LENGTH_OF_STAY\").count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Admit Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11303\n",
      "1 loop, best of 1: 2min 20s per loop\n"
     ]
    }
   ],
   "source": [
    "## Number of Diagnosis Codes\n",
    "%timeit -n1 -r1 print(texas_df.groupBy(\"ADMITTING_DIAGNOSIS\").count().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|ADMITTING_DIAGNOSIS|  count|\n",
      "+-------------------+-------+\n",
      "|               null|5032634|\n",
      "|               4019| 715086|\n",
      "|               V270| 308122|\n",
      "|              25000| 296101|\n",
      "|              V3000| 240512|\n",
      "|               4280| 239354|\n",
      "|               2724| 215109|\n",
      "|              41401| 188946|\n",
      "|               3051| 165513|\n",
      "|               5990| 155951|\n",
      "|              53081| 143961|\n",
      "|              42731| 140364|\n",
      "|               2859| 135045|\n",
      "|               V221| 125632|\n",
      "|               2449| 123831|\n",
      "|                496| 115170|\n",
      "|              V3001| 110404|\n",
      "|               2761| 100086|\n",
      "|                486|  98278|\n",
      "|               2768|  94414|\n",
      "|               V053|  91897|\n",
      "|              78650|  91359|\n",
      "|              40391|  81074|\n",
      "|               2720|  76036|\n",
      "|              27651|  72060|\n",
      "+-------------------+-------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_topN_group(texas_df, \"ADMITTING_DIAGNOSIS\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Patient Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52489\n"
     ]
    }
   ],
   "source": [
    "print(get_distinct_number(texas_df, \"ETHNICITY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|ETHNICITY|  count|\n",
      "+---------+-------+\n",
      "|     0.00|8905012|\n",
      "|        2|2043158|\n",
      "|        1| 765130|\n",
      "|  1182.00|  32114|\n",
      "|  2400.00|  28429|\n",
      "|  1773.00|  27205|\n",
      "|  2000.00|  26900|\n",
      "|   591.00|  23950|\n",
      "|  1604.00|  21883|\n",
      "|  1528.00|  21617|\n",
      "|  2160.00|  19552|\n",
      "|  1850.00|  19396|\n",
      "|  1406.00|  19042|\n",
      "|  1108.00|  18642|\n",
      "|  1456.00|  18492|\n",
      "|  2364.00|  17633|\n",
      "|  1000.00|  16816|\n",
      "|  1624.00|  16401|\n",
      "|  3000.00|  16201|\n",
      "|  3240.00|  15961|\n",
      "+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 loop, best of 1: 2min 15s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.groupBy(\"ETHNICITY\").count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|RACE|   count|\n",
      "+----+--------+\n",
      "| 111|15198686|\n",
      "|   4| 1802112|\n",
      "|   5|  600784|\n",
      "|   3|  354070|\n",
      "|   2|   45705|\n",
      "| 121|   40574|\n",
      "| 211|   37878|\n",
      "| 110|   27573|\n",
      "| 131|   16543|\n",
      "| 181|   11919|\n",
      "|   1|   10989|\n",
      "| 114|    5890|\n",
      "|null|    4777|\n",
      "| 641|     149|\n",
      "| 711|      96|\n",
      "| 210|      88|\n",
      "| 281|      77|\n",
      "| 171|      46|\n",
      "| 134|      37|\n",
      "|   *|      23|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "1 loop, best of 1: 59.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.groupBy(\"RACE\").count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n",
      "1 loop, best of 1: 1min 33s per loop\n"
     ]
    }
   ],
   "source": [
    "## Number of Diagnosis Codes\n",
    "%timeit -n1 -r1 print(texas_df.groupBy(\"PROVIDER_NAME\").count().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|       PROVIDER_NAME| count|\n",
      "+--------------------+------+\n",
      "|Parkland Memorial...|350607|\n",
      "|  Methodist Hospital|308712|\n",
      "|Baylor University...|266215|\n",
      "|Memorial Hermann ...|228010|\n",
      "|St Lukes Episcopa...|212507|\n",
      "|Harris Methodist-...|194237|\n",
      "|John Peter Smith ...|185952|\n",
      "|Ben Taub General ...|185004|\n",
      "|The Methodist Hos...|183536|\n",
      "|Scott & White Mem...|179892|\n",
      "|Presbyterian Hosp...|171138|\n",
      "|Memorial Hermann ...|169908|\n",
      "|McAllen Medical C...|167748|\n",
      "|Medical City Dall...|166803|\n",
      "|Seton Medical Center|165754|\n",
      "|Mother Frances Ho...|148905|\n",
      "| University Hospital|147828|\n",
      "|Clear Lake Region...|147820|\n",
      "|Baptist St Anthon...|140277|\n",
      "|Providence Memori...|137563|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_topN_group(texas_df, \"PROVIDER_NAME\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Admin Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|ADMIT_WEEKDAY|   count|\n",
      "+-------------+--------+\n",
      "|            4|10169480|\n",
      "|            5| 3624802|\n",
      "|            3| 2434129|\n",
      "|            2|  757208|\n",
      "|            1|  634216|\n",
      "|            6|  254662|\n",
      "|            7|  245730|\n",
      "|         null|   26204|\n",
      "|            *|   11678|\n",
      "|         RACE|      21|\n",
      "|ADMIT_WEEKDAY|       3|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_topN_group(texas_df, \"ADMIT_WEEKDAY\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Type & Source of Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique 'TYPE_OF_ADMISSION' is: 66.\n",
      "\n",
      "# of unique 'SOURCE_OF_ADMISSION' is: 269.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"TYPE_OF_ADMISSION\", \"SOURCE_OF_ADMISSION\"]:\n",
    "    print(\"# of unique '{}' is: {}.\\n\".format(col, get_distinct_number(texas_df, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|TYPE_OF_ADMISSION|   count|\n",
      "+-----------------+--------+\n",
      "|             null|12444656|\n",
      "|               US| 2852878|\n",
      "|                1| 1046899|\n",
      "|                3|  843946|\n",
      "|                2|  551669|\n",
      "|                4|  357630|\n",
      "|               MX|   26722|\n",
      "|                9|   11703|\n",
      "|                5|    6531|\n",
      "|               CL|    6256|\n",
      "|                *|    2917|\n",
      "|               KW|     827|\n",
      "|               CA|     807|\n",
      "|               SA|     578|\n",
      "|               AE|     388|\n",
      "|               GT|     306|\n",
      "|               HN|     282|\n",
      "|               VE|     263|\n",
      "|               PE|     236|\n",
      "|               PR|     202|\n",
      "+-----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-------+\n",
      "|SOURCE_OF_ADMISSION|  count|\n",
      "+-------------------+-------+\n",
      "|                201|2329758|\n",
      "|                113|1453804|\n",
      "|                  1|1115478|\n",
      "|                  7|1057671|\n",
      "|                439| 998204|\n",
      "|                029| 978970|\n",
      "|               null| 797329|\n",
      "|                215| 521499|\n",
      "|                453| 491380|\n",
      "|                141| 438149|\n",
      "|                085| 377514|\n",
      "|                121| 295304|\n",
      "|                061| 260466|\n",
      "|                339| 257554|\n",
      "|                355| 243140|\n",
      "|                157| 227150|\n",
      "|                167| 222743|\n",
      "|                303| 193451|\n",
      "|                245| 191401|\n",
      "|                039| 184296|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"TYPE_OF_ADMISSION\", \"SOURCE_OF_ADMISSION\"]:\n",
    "    get_topN_group(texas_df, col).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Payment Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_columns = [\"FIRST_PAYMENT_SRC\", \"SECONDARY_PAYMENT_SRC\"]\n",
    "[col in texas_df_columns for col in payment_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique 'FIRST_PAYMENT_SRC' is: 128632.\n",
      "\n",
      "# of unique 'SECONDARY_PAYMENT_SRC' is: 436.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in payment_columns:\n",
    "    print(\"# of unique '{}' is: {}.\\n\".format(col, get_distinct_number(texas_df, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|FIRST_PAYMENT_SRC|  count|\n",
      "+-----------------+-------+\n",
      "|             0.00|8407482|\n",
      "|               MA| 876556|\n",
      "|               MC| 607329|\n",
      "|               12| 333160|\n",
      "|               **| 284319|\n",
      "|               CI| 211086|\n",
      "|               HM| 189068|\n",
      "|               BL| 184924|\n",
      "|           570.00|  44882|\n",
      "|           940.00|  44560|\n",
      "|               16|  42895|\n",
      "|          1410.00|  40853|\n",
      "|          2400.00|  37779|\n",
      "|           470.00|  34157|\n",
      "|          1200.00|  32743|\n",
      "|               11|  28575|\n",
      "|          1400.00|  27982|\n",
      "|           600.00|  25565|\n",
      "|          1050.00|  25485|\n",
      "|               CH|  24857|\n",
      "+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------------+--------+\n",
      "|SECONDARY_PAYMENT_SRC|   count|\n",
      "+---------------------+--------+\n",
      "|                 0.00|15321575|\n",
      "|                 null| 1886829|\n",
      "|                   CI|  269486|\n",
      "|                   MC|  217141|\n",
      "|                   **|  154312|\n",
      "|                   BL|   78025|\n",
      "|                   12|   77040|\n",
      "|                   MA|   54239|\n",
      "|                   CH|   31699|\n",
      "|                   HM|   23498|\n",
      "|                   MB|   11252|\n",
      "|                   11|    7138|\n",
      "|               475.00|    5601|\n",
      "|                   OF|    2838|\n",
      "|                   16|    2490|\n",
      "|              1150.00|    2317|\n",
      "|               840.00|    1626|\n",
      "|               885.00|    1169|\n",
      "|               955.00|     930|\n",
      "|                   WC|     752|\n",
      "+---------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in payment_columns:\n",
    "    get_topN_group(texas_df, col).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Basic Stats on LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'requirement failed: Currently covariance calculation for columns with dataType StringType not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ea12a934af75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit -n1 -r1 texas_df.stat.cov(\"LENGTH_OF_STAY\", \"PAT_AGE\")'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\timeit.pyc\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\pyspark\\sql\\dataframe.pyc\u001b[0m in \u001b[0;36mcov\u001b[1;34m(self, col1, col2)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\pyspark\\sql\\dataframe.pyc\u001b[0m in \u001b[0;36mcov\u001b[1;34m(self, col1, col2)\u001b[0m\n\u001b[0;32m   1438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"col2 should be a string.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1440\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-2.1.1-bin-hadoop2.6\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: u'requirement failed: Currently covariance calculation for columns with dataType StringType not supported.'"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 texas_df.stat.cov(\"LENGTH_OF_STAY\", \"PAT_AGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "1 loop, best of 1: 1min 4s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 print(get_topN_group(texas_df, \"RACE\", False).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "1 loop, best of 1: 1min 3s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 print(texas_df.select(\"RACE\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
